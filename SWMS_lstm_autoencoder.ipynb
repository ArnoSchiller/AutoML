{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArnoSchiller/AutoML/blob/dev/SWMS_lstm_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca-tFfZhsZUB"
      },
      "source": [
        "## Define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHSeg9curlih"
      },
      "outputs": [],
      "source": [
        "# Select measurements \n",
        "measurements = []\n",
        "\n",
        "## tank group measurements \n",
        "prefix = \"mean_\"\n",
        "tank_group = 1\n",
        "for k in [1,2,3]:\n",
        "    measurements.append(prefix + \"sensor.o2.becken\" + str(tank_group) + str(k))\n",
        "    measurements.append(prefix + \"sensor.temp.becken\" + str(tank_group) + str(k))\n",
        "if tank_group < 3:\n",
        "    measurements.append(prefix + \"sensor.ws.sedi\" + str(tank_group))\n",
        "else:\n",
        "    measurements.append(prefix + \"sensor.ws.sed\" + str(tank_group))\n",
        "measurements.append(prefix + \"sensor.ws.bio\" + str(tank_group))\n",
        "measurements.append(prefix + \"allgemein_var.display_kollektor.leistung_p1\" + str(tank_group))\n",
        "\n",
        "\n",
        "mqtt_addition = \"tank_group=\" + str(tank_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaAhshB1uyn8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Datenbank und Messreihenauswahl\n",
        "database = 'plc' #@param [\"plc\", \"edge\", \"_internal\", \"InfluxDB_dev\",\"profec_test\"]\n",
        "\n",
        "#measurement = 'sensor.o2.becken12' #@param [\"sensor.feuchte_relativ.aussen\", \"sensor.o2.becken12\"] {allow-input: true}\n",
        "\n",
        "#train_min_time = '2021-10-07' #@param {type:\"date\"}\n",
        "train_max_time = '2021-10-03' #@param {type:\"date\"}\n",
        "train_duration = '23d' #@param {type:\"string\"}\n",
        "\n",
        "test_min_time = '2021-09-01' #@param {type:\"date\"}\n",
        "test_max_time = '2022-01-04' #@param {type:\"date\"}\n",
        "#test_duration = '19d' #@param {type:\"string\"}\n",
        "#### fds\n",
        "group_by = '5m' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIVoXFMiwCrd",
        "outputId": "a94caeb1-cbe1-4ab7-fd03-389e806d1579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database: plc\n",
            "Measurements: ['mean_sensor.o2.becken11', 'mean_sensor.temp.becken11', 'mean_sensor.o2.becken12', 'mean_sensor.temp.becken12', 'mean_sensor.o2.becken13', 'mean_sensor.temp.becken13', 'mean_sensor.ws.sedi1', 'mean_sensor.ws.bio1', 'mean_allgemein_var.display_kollektor.leistung_p11']\n",
            "Model: autoencoder_tg1_2 , window_length: 288\n"
          ]
        }
      ],
      "source": [
        "#@title Model parameters\n",
        "model_name = \"autoencoder_tg1_2\"   #@param [\"lstm_autoencoder_1\"] {allow-input: true}\n",
        "\n",
        "epochs = 100            #@param {type:\"integer\"}\n",
        "batch_size = 32         #@param {type:\"integer\"}\n",
        "window_length = 12 * 24      #@param {type:\"integer\"}\n",
        "sequence_length = '1d'\n",
        "sequence_step = '1d'\n",
        "\n",
        "print(\"Database:\", database)\n",
        "print(\"Measurements:\", measurements)\n",
        "#print(\"Training:   From\", train_min_time, \"to\", train_max_time)\n",
        "#print(\"Testing:    From\", test_min_time, \"to\", test_max_time)\n",
        "print(\"Model:\", model_name, \", window_length:\", window_length)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mOx7vh_skiY"
      },
      "source": [
        "## Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fitrJKgzFA4w",
        "outputId": "05840454-c53c-4920-8aa5-310d893bb79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/TimeSeriesAnalysis\n",
            "\u001b[0m\u001b[01;34mautoencoder_tg1_1\u001b[0m/  \u001b[01;34mlstm_autoencoder_1\u001b[0m/          training_data.csv\n",
            "\u001b[01;34mautoencoder_tg1_2\u001b[0m/  SWMS_lstm_autoencoder.ipynb  validation_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "%cd /content/gdrive/My Drive/TimeSeriesAnalysis/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmh2zGuYtaoL"
      },
      "source": [
        "## Define functions for data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypTzYmiS202o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "\n",
        "def generate_datasets_for_training(data, window_size,scale=True, scaler_type=StandardScaler):\n",
        "    _l = len(data) \n",
        "    data = scaler_type().fit_transform(data)\n",
        "    Xs = []\n",
        "    Ys = []\n",
        "    for i in range(0, (_l - window_size)):\n",
        "    # because this is an autoencoder - our Ys are the same as our Xs. No need to pull the next sequence of values\n",
        "        Xs.append(data[i:i+window_size])\n",
        "        Ys.append(data[i:i+window_size])\n",
        "    tr_x, ts_x, tr_y, ts_y = [np.array(x) for x in train_test_split(Xs, Ys)]\n",
        "    assert tr_x.shape[2] == ts_x.shape[2] == (data.shape[1] if (type(data) == np.ndarray) else len(data))\n",
        "    return  (tr_x.shape[2], tr_x, tr_y, ts_x, ts_y)\n",
        "\n",
        "\n",
        "def generate_datasets_for_validation(data, window_size,scale=True, scaler_type=StandardScaler):\n",
        "    _l = len(data) \n",
        "    data = scaler_type().fit_transform(data)\n",
        "    Xs = []\n",
        "    Ys = []\n",
        "    for i in range(0, (_l - window_size)):\n",
        "    # because this is an autoencoder - our Ys are the same as our Xs. No need to pull the next sequence of values\n",
        "        Xs.append(data[i:i+window_size])\n",
        "        Ys.append(data[i:i+window_size])\n",
        "    tr_x, ts_x, tr_y, ts_y = [np.array(x) for x in train_test_split(Xs, Ys, test_size=0.99)]\n",
        "    assert tr_x.shape[2] == ts_x.shape[2] == (data.shape[1] if (type(data) == np.ndarray) else len(data))\n",
        "    return  (tr_x.shape[2], tr_x, tr_y, ts_x, ts_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNTQfZIGssHc"
      },
      "source": [
        "## Load data from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "DfexF3Xf2ut4",
        "outputId": "b467abc5-af21-4cfc-96f9-7542fb837956"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-79d99ee2-8c7d-40e9-9899-9c54ecccd467\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_allgemein_var.display_kollektor.leistung_p11</th>\n",
              "      <th>mean_allgemein_var.display_kollektor.leistung_p12</th>\n",
              "      <th>mean_allgemein_var.display_kollektor.leistung_p13</th>\n",
              "      <th>mean_sensor.Volumenstrom.verdichter</th>\n",
              "      <th>mean_sensor.druck.verdichter</th>\n",
              "      <th>mean_sensor.druck.verdichter_leitungsende</th>\n",
              "      <th>mean_sensor.feuchte_relativ.aussen</th>\n",
              "      <th>mean_sensor.feuchte_relativ.halle_hinten</th>\n",
              "      <th>mean_sensor.feuchte_relativ.halle_vorn</th>\n",
              "      <th>mean_sensor.o2.becken11</th>\n",
              "      <th>mean_sensor.o2.becken12</th>\n",
              "      <th>mean_sensor.o2.becken13</th>\n",
              "      <th>mean_sensor.o2.becken21</th>\n",
              "      <th>mean_sensor.o2.becken22</th>\n",
              "      <th>mean_sensor.o2.becken23</th>\n",
              "      <th>mean_sensor.o2.becken31</th>\n",
              "      <th>mean_sensor.o2.becken32</th>\n",
              "      <th>mean_sensor.o2.becken33</th>\n",
              "      <th>mean_sensor.temp.becken11</th>\n",
              "      <th>mean_sensor.temp.becken12</th>\n",
              "      <th>mean_sensor.temp.becken13</th>\n",
              "      <th>mean_sensor.temp.becken21</th>\n",
              "      <th>mean_sensor.temp.becken22</th>\n",
              "      <th>mean_sensor.temp.becken23</th>\n",
              "      <th>mean_sensor.temp.becken31</th>\n",
              "      <th>mean_sensor.temp.becken32</th>\n",
              "      <th>mean_sensor.temp.becken33</th>\n",
              "      <th>mean_sensor.temp.halle_gesamt_mittelwert</th>\n",
              "      <th>mean_sensor.temp.halle_hinten</th>\n",
              "      <th>mean_sensor.temp.halle_vorn</th>\n",
              "      <th>mean_sensor.temp.luft_aussen</th>\n",
              "      <th>mean_sensor.temp.pl11</th>\n",
              "      <th>mean_sensor.temp.pl12</th>\n",
              "      <th>mean_sensor.temp.pl21</th>\n",
              "      <th>mean_sensor.temp.pl22</th>\n",
              "      <th>mean_sensor.temp.vorlauf_heizung</th>\n",
              "      <th>mean_sensor.truebung.storage</th>\n",
              "      <th>mean_sensor.ws.bio1</th>\n",
              "      <th>mean_sensor.ws.bio2</th>\n",
              "      <th>mean_sensor.ws.bio3</th>\n",
              "      <th>mean_sensor.ws.pl11</th>\n",
              "      <th>mean_sensor.ws.pl12</th>\n",
              "      <th>mean_sensor.ws.pl21</th>\n",
              "      <th>mean_sensor.ws.pl22</th>\n",
              "      <th>mean_sensor.ws.reservoir</th>\n",
              "      <th>mean_sensor.ws.sed3</th>\n",
              "      <th>mean_sensor.ws.sedi1</th>\n",
              "      <th>mean_sensor.ws.sedi2</th>\n",
              "      <th>mean_sensor.ws.storage_kollektor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>737.267200</td>\n",
              "      <td>0.409997</td>\n",
              "      <td>0.410973</td>\n",
              "      <td>0.837752</td>\n",
              "      <td>0.852396</td>\n",
              "      <td>0.836157</td>\n",
              "      <td>6.260672</td>\n",
              "      <td>6.141230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.692525</td>\n",
              "      <td>6.458651</td>\n",
              "      <td>6.379241</td>\n",
              "      <td>6.687549</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.469140</td>\n",
              "      <td>29.507230</td>\n",
              "      <td>28.920880</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.945530</td>\n",
              "      <td>28.919940</td>\n",
              "      <td>29.049360</td>\n",
              "      <td>29.005780</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.994700</td>\n",
              "      <td>29.177380</td>\n",
              "      <td>29.391350</td>\n",
              "      <td>28.964380</td>\n",
              "      <td>13.258530</td>\n",
              "      <td>28.86397</td>\n",
              "      <td>28.703390</td>\n",
              "      <td>28.33665</td>\n",
              "      <td>28.078410</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>210.09800</td>\n",
              "      <td>2.288115</td>\n",
              "      <td>2.59943</td>\n",
              "      <td>2.602882</td>\n",
              "      <td>0.028572</td>\n",
              "      <td>0.034359</td>\n",
              "      <td>-0.017360</td>\n",
              "      <td>0.052805</td>\n",
              "      <td>0.183732</td>\n",
              "      <td>2.690661</td>\n",
              "      <td>2.353217</td>\n",
              "      <td>2.721404</td>\n",
              "      <td>0.399653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>737.122887</td>\n",
              "      <td>0.409994</td>\n",
              "      <td>0.410976</td>\n",
              "      <td>0.837217</td>\n",
              "      <td>0.852399</td>\n",
              "      <td>0.835894</td>\n",
              "      <td>6.266599</td>\n",
              "      <td>6.141356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.685192</td>\n",
              "      <td>6.468863</td>\n",
              "      <td>6.369840</td>\n",
              "      <td>6.681170</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468895</td>\n",
              "      <td>29.507293</td>\n",
              "      <td>28.920849</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.946653</td>\n",
              "      <td>28.920045</td>\n",
              "      <td>29.049683</td>\n",
              "      <td>29.006269</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.994939</td>\n",
              "      <td>29.184094</td>\n",
              "      <td>29.391471</td>\n",
              "      <td>28.977641</td>\n",
              "      <td>13.248451</td>\n",
              "      <td>28.86397</td>\n",
              "      <td>28.702377</td>\n",
              "      <td>28.33665</td>\n",
              "      <td>28.076385</td>\n",
              "      <td>37.493333</td>\n",
              "      <td>209.70016</td>\n",
              "      <td>2.290936</td>\n",
              "      <td>2.59943</td>\n",
              "      <td>2.602954</td>\n",
              "      <td>0.028597</td>\n",
              "      <td>0.034383</td>\n",
              "      <td>-0.017336</td>\n",
              "      <td>0.052805</td>\n",
              "      <td>0.183732</td>\n",
              "      <td>2.690733</td>\n",
              "      <td>2.354447</td>\n",
              "      <td>2.722224</td>\n",
              "      <td>0.404379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>736.978573</td>\n",
              "      <td>0.409992</td>\n",
              "      <td>0.410978</td>\n",
              "      <td>0.836681</td>\n",
              "      <td>0.852401</td>\n",
              "      <td>0.835631</td>\n",
              "      <td>6.272525</td>\n",
              "      <td>6.141482</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.677859</td>\n",
              "      <td>6.479075</td>\n",
              "      <td>6.360439</td>\n",
              "      <td>6.674791</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468649</td>\n",
              "      <td>29.507357</td>\n",
              "      <td>28.920817</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.947777</td>\n",
              "      <td>28.920149</td>\n",
              "      <td>29.050005</td>\n",
              "      <td>29.006759</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.995179</td>\n",
              "      <td>29.190808</td>\n",
              "      <td>29.391591</td>\n",
              "      <td>28.990903</td>\n",
              "      <td>13.238373</td>\n",
              "      <td>28.86397</td>\n",
              "      <td>28.701365</td>\n",
              "      <td>28.33665</td>\n",
              "      <td>28.074359</td>\n",
              "      <td>37.486667</td>\n",
              "      <td>209.30232</td>\n",
              "      <td>2.293757</td>\n",
              "      <td>2.59943</td>\n",
              "      <td>2.603027</td>\n",
              "      <td>0.028621</td>\n",
              "      <td>0.034408</td>\n",
              "      <td>-0.017312</td>\n",
              "      <td>0.052805</td>\n",
              "      <td>0.183732</td>\n",
              "      <td>2.690806</td>\n",
              "      <td>2.355676</td>\n",
              "      <td>2.723044</td>\n",
              "      <td>0.409105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>736.834260</td>\n",
              "      <td>0.409989</td>\n",
              "      <td>0.410981</td>\n",
              "      <td>0.836146</td>\n",
              "      <td>0.852403</td>\n",
              "      <td>0.835368</td>\n",
              "      <td>6.278452</td>\n",
              "      <td>6.141608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.670526</td>\n",
              "      <td>6.489288</td>\n",
              "      <td>6.351038</td>\n",
              "      <td>6.668412</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468404</td>\n",
              "      <td>29.507420</td>\n",
              "      <td>28.920786</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.948900</td>\n",
              "      <td>28.920254</td>\n",
              "      <td>29.050328</td>\n",
              "      <td>29.007248</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.995418</td>\n",
              "      <td>29.197522</td>\n",
              "      <td>29.391712</td>\n",
              "      <td>29.004164</td>\n",
              "      <td>13.228294</td>\n",
              "      <td>28.86397</td>\n",
              "      <td>28.700352</td>\n",
              "      <td>28.33665</td>\n",
              "      <td>28.072334</td>\n",
              "      <td>37.480000</td>\n",
              "      <td>208.90448</td>\n",
              "      <td>2.296578</td>\n",
              "      <td>2.59943</td>\n",
              "      <td>2.603099</td>\n",
              "      <td>0.028645</td>\n",
              "      <td>0.034432</td>\n",
              "      <td>-0.017288</td>\n",
              "      <td>0.052805</td>\n",
              "      <td>0.183732</td>\n",
              "      <td>2.690878</td>\n",
              "      <td>2.356906</td>\n",
              "      <td>2.723863</td>\n",
              "      <td>0.413831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>736.689947</td>\n",
              "      <td>0.409987</td>\n",
              "      <td>0.410983</td>\n",
              "      <td>0.835611</td>\n",
              "      <td>0.852406</td>\n",
              "      <td>0.835106</td>\n",
              "      <td>6.284379</td>\n",
              "      <td>6.141735</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.663193</td>\n",
              "      <td>6.499500</td>\n",
              "      <td>6.341637</td>\n",
              "      <td>6.662033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.468158</td>\n",
              "      <td>29.507483</td>\n",
              "      <td>28.920755</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.950023</td>\n",
              "      <td>28.920359</td>\n",
              "      <td>29.050651</td>\n",
              "      <td>29.007737</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>28.995657</td>\n",
              "      <td>29.204236</td>\n",
              "      <td>29.391833</td>\n",
              "      <td>29.017425</td>\n",
              "      <td>13.218215</td>\n",
              "      <td>28.86397</td>\n",
              "      <td>28.699339</td>\n",
              "      <td>28.33665</td>\n",
              "      <td>28.070309</td>\n",
              "      <td>37.473333</td>\n",
              "      <td>208.50664</td>\n",
              "      <td>2.299399</td>\n",
              "      <td>2.59943</td>\n",
              "      <td>2.603171</td>\n",
              "      <td>0.028669</td>\n",
              "      <td>0.034456</td>\n",
              "      <td>-0.017264</td>\n",
              "      <td>0.052805</td>\n",
              "      <td>0.183732</td>\n",
              "      <td>2.690950</td>\n",
              "      <td>2.358136</td>\n",
              "      <td>2.724683</td>\n",
              "      <td>0.418556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79d99ee2-8c7d-40e9-9899-9c54ecccd467')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79d99ee2-8c7d-40e9-9899-9c54ecccd467 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79d99ee2-8c7d-40e9-9899-9c54ecccd467');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   mean_allgemein_var.display_kollektor.leistung_p11  ...  mean_sensor.ws.storage_kollektor\n",
              "0                                               59.0  ...                          0.399653\n",
              "1                                               59.0  ...                          0.404379\n",
              "2                                               59.0  ...                          0.409105\n",
              "3                                               59.0  ...                          0.413831\n",
              "4                                               59.0  ...                          0.418556\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_data = pd.read_csv(\"training_data.csv\")\n",
        "train_data = train_data.drop(\"time\",axis=1)\n",
        "train_data.head()\n",
        "\n",
        "test_data = pd.read_csv(\"validation_data.csv\")\n",
        "test_data = test_data.drop(\"time\", axis=1)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FexXVPQxtCX9"
      },
      "source": [
        "## Load data from Influx DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvaLvUoaww3h",
        "outputId": "8b920f82-6aa3-491e-dcfd-1a8faaac2b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting influxdb\n",
            "  Downloading influxdb-5.3.1-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 71 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from influxdb) (2.8.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from influxdb) (1.0.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from influxdb) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.17.0 in /usr/local/lib/python3.7/dist-packages (from influxdb) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from influxdb) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.0->influxdb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.0->influxdb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.0->influxdb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.0->influxdb) (2.10)\n",
            "Installing collected packages: influxdb\n",
            "Successfully installed influxdb-5.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install influxdb\n",
        "from influxdb import InfluxDBClient, DataFrameClient\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yy6f6xxxBST"
      },
      "outputs": [],
      "source": [
        "def parse_time(time_str):\n",
        "    regex = re.compile(r'((?P<days>\\d+?)d)?((?P<hours>\\d+?)h)?((?P<minutes>\\d+?)m)?((?P<seconds>\\d+?)s)?((?P<milliseconds>\\d+?)ms)?')\n",
        "    parts = regex.match(time_str)\n",
        "    if not parts:\n",
        "        return\n",
        "    parts = parts.groupdict()\n",
        "    time_params = {}\n",
        "    for name, param in parts.items():\n",
        "        if param:\n",
        "            time_params[name] = int(param)\n",
        "    return timedelta(**time_params)\n",
        "\n",
        "        \n",
        "def get_latest_value_from_influxDB(measurements, database, min_time_ms):\n",
        "    q = 'SELECT mean(*) FROM {db} WHERE time < {min_time}ms GROUP BY * ORDER BY DESC LIMIT 1'.format(\n",
        "        db = database,\n",
        "        min_time = min_time_ms)\n",
        "    data = pd.DataFrame(client.query(q).get_points())\n",
        "    # set timestamp to index\n",
        "    data.set_index('time', drop=True, inplace=True)\n",
        "    data = data[measurements]\n",
        "\n",
        "    return data    \n",
        "        \n",
        "def get_data_from_influxDB(measurements, database, min_time_ms, max_time_ms, group_by):\n",
        "    q = 'SELECT mean(*) FROM {db} WHERE time >= {min_time}ms AND time < {max_time}ms GROUP BY time({gb}) fill(previous)'.format(\n",
        "        db = database,\n",
        "        min_time = min_time_ms,\n",
        "        max_time = max_time_ms,\n",
        "        gb = group_by)\n",
        "    #print(q)\n",
        "    data = pd.DataFrame(client.query(q).get_points())\n",
        "    #print(data)\n",
        "    if(data.empty):\n",
        "        return None\n",
        "    \n",
        "    #print(data)\n",
        "    # set timestamp to index\n",
        "    data.set_index('time', drop=True, inplace=True)\n",
        "    data = data[measurements]\n",
        "\n",
        "    #print(\"Total values NaN\", data.isna().values.sum())\n",
        "    #print(data.isna().index.all())\n",
        "    \n",
        "    last_val = get_latest_value_from_influxDB(measurements, database, min_time_ms)\n",
        "\n",
        "    row_idx = 0\n",
        "    while row_idx < len(data.index):\n",
        "        row = data.iloc[row_idx]\n",
        "        values_nan = row.isna().values.sum()\n",
        "\n",
        "        if values_nan > 0:\n",
        "            #print(\"Values NaN in row\", row_idx, \":\", values_nan)\n",
        "            nan_idx = row.isna().index\n",
        "            for idx in nan_idx:\n",
        "                data.loc[data.index[row_idx], idx] = last_val.loc[last_val.index[0], idx]\n",
        "        else: \n",
        "            #print(\"Total values NaN after adding latest values\", data.isna().values.sum())\n",
        "            break\n",
        "        row_idx += 1\n",
        "\n",
        "    #print(data.columns)\n",
        "    #print(data)\n",
        "\n",
        "    return data    \n",
        "\n",
        "def convert_data_to_numpy(data):\n",
        "    return data.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnDyvNKYw29k"
      },
      "outputs": [],
      "source": [
        "#train_min_time_ms = int(datetime.fromisoformat(train_min_time).timestamp() * 1000)\n",
        "train_max_time_ms = datetime.fromisoformat(train_max_time)\n",
        "train_min_time_ms = int((train_max_time_ms - parse_time(train_duration)).timestamp() * 1000)\n",
        "train_max_time_ms = int(train_max_time_ms.timestamp() * 1000)\n",
        "\n",
        "test_min_time_ms = int(datetime.fromisoformat(test_min_time).timestamp() * 1000)\n",
        "test_max_time_ms = datetime.fromisoformat(test_max_time)\n",
        "#test_min_time_ms = int((test_max_time_ms - parse_time(test_duration)).timestamp() * 1000)\n",
        "test_max_time_ms = int(test_max_time_ms.timestamp() * 1000)\n",
        "\n",
        "client = InfluxDBClient(host='demo2.iotstack.co', port=8086, \n",
        "                        username=\"telegraf\", password=\"tiguitto\", \n",
        "                        ssl=True, verify_ssl=True)\n",
        "client.switch_database(database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOEYT4xytFw9",
        "outputId": "febc4261-dd8a-47be-b447-a7a05dc63930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59616\n",
            "\n",
            "\n",
            " #################################################################################################### \n",
            "\n",
            "\n",
            "324000\n"
          ]
        }
      ],
      "source": [
        "train_data = convert_data_to_numpy(get_data_from_influxDB(measurements=measurements,\n",
        "                                                          database=database,\n",
        "                                                          min_time_ms=train_min_time_ms,\n",
        "                                                          max_time_ms=train_max_time_ms,\n",
        "                                                          group_by=group_by))\n",
        "\n",
        "print(train_data.size)\n",
        "print('\\n'*2, '#'*100,'\\n'*2)\n",
        "\n",
        "test_data = convert_data_to_numpy(get_data_from_influxDB(measurements=measurements,\n",
        "                                                          database=database,\n",
        "                                                          min_time_ms=test_min_time_ms,\n",
        "                                                          max_time_ms=test_max_time_ms,\n",
        "                                                          group_by=group_by))\n",
        "print(test_data.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sYzOpwrtije"
      },
      "source": [
        "## Build, train and save the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0WMUoYVe0y3"
      },
      "source": [
        "Source: https://towardsdatascience.com/using-lstm-autoencoders-on-multidimensional-time-series-data-f5a7a51b29a1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTwNF2BUXElO"
      },
      "outputs": [],
      "source": [
        "from keras import metrics\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1SmPirj-hjh",
        "outputId": "43a74e4b-2c66-4020-d54b-8ce880ec472e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (LSTM)            (None, 288, 64)           18944     \n",
            "                                                                 \n",
            " encoder_2 (LSTM)            (None, 288, 32)           12416     \n",
            "                                                                 \n",
            " encoder_3 (LSTM)            (None, 16)                3136      \n",
            "                                                                 \n",
            " encoder_decoder_bridge (Rep  (None, 288, 16)          0         \n",
            " eatVector)                                                      \n",
            "                                                                 \n",
            " decoder_1 (LSTM)            (None, 288, 16)           2112      \n",
            "                                                                 \n",
            " decoder_2 (LSTM)            (None, 288, 32)           6272      \n",
            "                                                                 \n",
            " decoder_3 (LSTM)            (None, 288, 64)           24832     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 288, 9)           585       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,297\n",
            "Trainable params: 68,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "149/149 [==============================] - 123s 753ms/step - loss: 0.4624 - val_loss: 0.4081\n",
            "Epoch 2/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.3883 - val_loss: 0.3894\n",
            "Epoch 3/100\n",
            "149/149 [==============================] - 110s 741ms/step - loss: 0.3793 - val_loss: 0.3850\n",
            "Epoch 4/100\n",
            "149/149 [==============================] - 110s 740ms/step - loss: 0.3772 - val_loss: 0.3800\n",
            "Epoch 5/100\n",
            "149/149 [==============================] - 110s 741ms/step - loss: 0.3740 - val_loss: 0.3724\n",
            "Epoch 6/100\n",
            "149/149 [==============================] - 110s 741ms/step - loss: 0.3758 - val_loss: 0.3725\n",
            "Epoch 7/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.3660 - val_loss: 0.3684\n",
            "Epoch 8/100\n",
            "149/149 [==============================] - 110s 736ms/step - loss: 0.3553 - val_loss: 0.3562\n",
            "Epoch 9/100\n",
            "149/149 [==============================] - 112s 749ms/step - loss: 0.3478 - val_loss: 0.3555\n",
            "Epoch 10/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.3510 - val_loss: 0.3523\n",
            "Epoch 11/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.3415 - val_loss: 0.3391\n",
            "Epoch 12/100\n",
            "149/149 [==============================] - 109s 734ms/step - loss: 0.3370 - val_loss: 0.3405\n",
            "Epoch 13/100\n",
            "149/149 [==============================] - 109s 734ms/step - loss: 0.3384 - val_loss: 0.3323\n",
            "Epoch 14/100\n",
            "149/149 [==============================] - 110s 736ms/step - loss: 0.3215 - val_loss: 0.3247\n",
            "Epoch 15/100\n",
            "149/149 [==============================] - 112s 749ms/step - loss: 0.3188 - val_loss: 0.3175\n",
            "Epoch 16/100\n",
            "149/149 [==============================] - 110s 736ms/step - loss: 0.3124 - val_loss: 0.3183\n",
            "Epoch 17/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.3134 - val_loss: 0.3153\n",
            "Epoch 18/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.3068 - val_loss: 0.3103\n",
            "Epoch 19/100\n",
            "149/149 [==============================] - 111s 743ms/step - loss: 0.3020 - val_loss: 0.3009\n",
            "Epoch 20/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2977 - val_loss: 0.2965\n",
            "Epoch 21/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2957 - val_loss: 0.2960\n",
            "Epoch 22/100\n",
            "149/149 [==============================] - 110s 738ms/step - loss: 0.2901 - val_loss: 0.2893\n",
            "Epoch 23/100\n",
            "149/149 [==============================] - 110s 736ms/step - loss: 0.2877 - val_loss: 0.2860\n",
            "Epoch 24/100\n",
            "149/149 [==============================] - 110s 741ms/step - loss: 0.2825 - val_loss: 0.2808\n",
            "Epoch 25/100\n",
            "149/149 [==============================] - 110s 742ms/step - loss: 0.2751 - val_loss: 0.2742\n",
            "Epoch 26/100\n",
            "149/149 [==============================] - 110s 741ms/step - loss: 0.2759 - val_loss: 0.2771\n",
            "Epoch 27/100\n",
            "149/149 [==============================] - 111s 743ms/step - loss: 0.2763 - val_loss: 0.2713\n",
            "Epoch 28/100\n",
            "149/149 [==============================] - 111s 745ms/step - loss: 0.2677 - val_loss: 0.2687\n",
            "Epoch 29/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.2692 - val_loss: 0.3063\n",
            "Epoch 30/100\n",
            "149/149 [==============================] - 111s 743ms/step - loss: 0.2775 - val_loss: 0.2902\n",
            "Epoch 31/100\n",
            "149/149 [==============================] - 110s 742ms/step - loss: 0.2656 - val_loss: 0.2562\n",
            "Epoch 32/100\n",
            "149/149 [==============================] - 110s 738ms/step - loss: 0.2565 - val_loss: 0.2610\n",
            "Epoch 33/100\n",
            "149/149 [==============================] - 111s 743ms/step - loss: 0.2506 - val_loss: 0.2477\n",
            "Epoch 34/100\n",
            "149/149 [==============================] - 110s 742ms/step - loss: 0.2454 - val_loss: 0.2439\n",
            "Epoch 35/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.2506 - val_loss: 0.2444\n",
            "Epoch 36/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2469 - val_loss: 0.2515\n",
            "Epoch 37/100\n",
            "149/149 [==============================] - 110s 740ms/step - loss: 0.2406 - val_loss: 0.2411\n",
            "Epoch 38/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2330 - val_loss: 0.2438\n",
            "Epoch 39/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2337 - val_loss: 0.2283\n",
            "Epoch 40/100\n",
            "149/149 [==============================] - 111s 742ms/step - loss: 0.2216 - val_loss: 0.2176\n",
            "Epoch 41/100\n",
            "149/149 [==============================] - 110s 741ms/step - loss: 0.2225 - val_loss: 0.2341\n",
            "Epoch 42/100\n",
            "149/149 [==============================] - 110s 738ms/step - loss: 0.2237 - val_loss: 0.2345\n",
            "Epoch 43/100\n",
            "149/149 [==============================] - 109s 734ms/step - loss: 0.2186 - val_loss: 0.2218\n",
            "Epoch 44/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2301 - val_loss: 0.2325\n",
            "Epoch 45/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2262 - val_loss: 0.2248\n",
            "Epoch 46/100\n",
            "149/149 [==============================] - 110s 738ms/step - loss: 0.2170 - val_loss: 0.2122\n",
            "Epoch 47/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.2088 - val_loss: 0.2062\n",
            "Epoch 48/100\n",
            "149/149 [==============================] - 109s 732ms/step - loss: 0.2022 - val_loss: 0.2089\n",
            "Epoch 49/100\n",
            "149/149 [==============================] - 109s 734ms/step - loss: 0.1990 - val_loss: 0.1952\n",
            "Epoch 50/100\n",
            "149/149 [==============================] - 111s 747ms/step - loss: 0.2105 - val_loss: 0.2125\n",
            "Epoch 51/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.2063 - val_loss: 0.2048\n",
            "Epoch 52/100\n",
            "149/149 [==============================] - 110s 740ms/step - loss: 0.2038 - val_loss: 0.2108\n",
            "Epoch 53/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.1996 - val_loss: 0.2254\n",
            "Epoch 54/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2159 - val_loss: 0.1966\n",
            "Epoch 55/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.1984 - val_loss: 0.1986\n",
            "Epoch 56/100\n",
            "149/149 [==============================] - 111s 746ms/step - loss: 0.2202 - val_loss: 0.2432\n",
            "Epoch 57/100\n",
            "149/149 [==============================] - 110s 738ms/step - loss: 0.2187 - val_loss: 0.2071\n",
            "Epoch 58/100\n",
            "149/149 [==============================] - 110s 736ms/step - loss: 0.2065 - val_loss: 0.2077\n",
            "Epoch 59/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.1960 - val_loss: 0.1985\n",
            "Epoch 60/100\n",
            "149/149 [==============================] - 110s 739ms/step - loss: 0.1951 - val_loss: 0.2078\n",
            "Epoch 61/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.1963 - val_loss: 0.1877\n",
            "Epoch 62/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.2460 - val_loss: 0.2538\n",
            "Epoch 63/100\n",
            "149/149 [==============================] - 109s 734ms/step - loss: 0.2306 - val_loss: 0.2152\n",
            "Epoch 64/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.2123 - val_loss: 0.2092\n",
            "Epoch 65/100\n",
            "149/149 [==============================] - 110s 735ms/step - loss: 0.2019 - val_loss: 0.1918\n",
            "Epoch 66/100\n",
            "149/149 [==============================] - 109s 732ms/step - loss: 0.2145 - val_loss: 0.2213\n",
            "Epoch 67/100\n",
            "149/149 [==============================] - 109s 732ms/step - loss: 0.2053 - val_loss: 0.2049\n",
            "Epoch 68/100\n",
            "149/149 [==============================] - 110s 742ms/step - loss: 0.2010 - val_loss: 0.1991\n",
            "Epoch 69/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1963 - val_loss: 0.1949\n",
            "Epoch 70/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1893 - val_loss: 0.1823\n",
            "Epoch 71/100\n",
            "149/149 [==============================] - 110s 736ms/step - loss: 0.1790 - val_loss: 0.1710\n",
            "Epoch 72/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.1839 - val_loss: 0.1818\n",
            "Epoch 73/100\n",
            "149/149 [==============================] - 109s 732ms/step - loss: 0.1793 - val_loss: 0.1840\n",
            "Epoch 74/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1909 - val_loss: 0.1850\n",
            "Epoch 75/100\n",
            "149/149 [==============================] - 109s 732ms/step - loss: 0.1990 - val_loss: 0.1870\n",
            "Epoch 76/100\n",
            "149/149 [==============================] - 110s 738ms/step - loss: 0.2035 - val_loss: 0.2136\n",
            "Epoch 77/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.1957 - val_loss: 0.1951\n",
            "Epoch 78/100\n",
            "149/149 [==============================] - 110s 742ms/step - loss: 0.1917 - val_loss: 0.1909\n",
            "Epoch 79/100\n",
            "149/149 [==============================] - 110s 736ms/step - loss: 0.1922 - val_loss: 0.2095\n",
            "Epoch 80/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.2243 - val_loss: 0.2198\n",
            "Epoch 81/100\n",
            "149/149 [==============================] - 109s 734ms/step - loss: 0.2074 - val_loss: 0.2209\n",
            "Epoch 82/100\n",
            "149/149 [==============================] - 109s 730ms/step - loss: 0.1985 - val_loss: 0.2224\n",
            "Epoch 83/100\n",
            "149/149 [==============================] - 109s 729ms/step - loss: 0.2009 - val_loss: 0.2364\n",
            "Epoch 84/100\n",
            "149/149 [==============================] - 110s 741ms/step - loss: 0.2087 - val_loss: 0.2045\n",
            "Epoch 85/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.2003 - val_loss: 0.1837\n",
            "Epoch 86/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1911 - val_loss: 0.1869\n",
            "Epoch 87/100\n",
            "149/149 [==============================] - 109s 734ms/step - loss: 0.1822 - val_loss: 0.1759\n",
            "Epoch 88/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.1709 - val_loss: 0.1758\n",
            "Epoch 89/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1896 - val_loss: 0.1882\n",
            "Epoch 90/100\n",
            "149/149 [==============================] - 109s 731ms/step - loss: 0.1805 - val_loss: 0.1954\n",
            "Epoch 91/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.2056 - val_loss: 0.1913\n",
            "Epoch 92/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.1833 - val_loss: 0.1870\n",
            "Epoch 93/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1998 - val_loss: 0.2260\n",
            "Epoch 94/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.2063 - val_loss: 0.2004\n",
            "Epoch 95/100\n",
            "149/149 [==============================] - 109s 730ms/step - loss: 0.1959 - val_loss: 0.1934\n",
            "Epoch 96/100\n",
            "149/149 [==============================] - 110s 737ms/step - loss: 0.1908 - val_loss: 0.1924\n",
            "Epoch 97/100\n",
            "149/149 [==============================] - 109s 735ms/step - loss: 0.1887 - val_loss: 0.1842\n",
            "Epoch 98/100\n",
            "149/149 [==============================] - 109s 731ms/step - loss: 0.1829 - val_loss: 0.1911\n",
            "Epoch 99/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1823 - val_loss: 0.1740\n",
            "Epoch 100/100\n",
            "149/149 [==============================] - 109s 733ms/step - loss: 0.1805 - val_loss: 0.1903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: autoencoder_tg1_2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: autoencoder_tg1_2/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f859b3e9ed0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f85976cf7d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f85976aaad0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f859746d710> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f859746d750> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f859743fd90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=1e-2, patience=5, verbose=0, mode='auto',\n",
        "    baseline=None, restore_best_weights=True)\n",
        "\n",
        "feats, X, Y, XX, YY = generate_datasets_for_training(train_data, window_length)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, window_length, feats), return_sequences=True, name='encoder_1'))\n",
        "model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))\n",
        "model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=False, name='encoder_3'))\n",
        "model.add(keras.layers.RepeatVector(window_length, name='encoder_decoder_bridge'))\n",
        "model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=True, name='decoder_1'))\n",
        "model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='decoder_2'))\n",
        "model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', return_sequences=True, name='decoder_3'))\n",
        "model.add(keras.layers.TimeDistributed(keras.layers.Dense(feats)))\n",
        "model.compile(loss=\"mse\",optimizer='adam')\n",
        "model.build()\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(x=X, y=Y, validation_data=(XX, YY), epochs=epochs, batch_size=batch_size, shuffle=True) #, callbacks=[early_stop])\n",
        "model.save(model_name, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Jv0nxAib_PLJ",
        "outputId": "9ec0cc03-df63-40de-9461-ccba5bc73217"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukh-z83xt2wa"
      },
      "source": [
        "## Load model from file and run on data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp2lGbbTYIHZ",
        "outputId": "1f8ba5c6-71ca-4289-dcd6-91de69164042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: paho-mqtt in /usr/local/lib/python3.7/dist-packages (1.6.1)\n"
          ]
        }
      ],
      "source": [
        "client = InfluxDBClient(host='demo2.iotstack.co', port=8086, \n",
        "                        username=\"telegraf\", password=\"tiguitto\", \n",
        "                        ssl=True, verify_ssl=True)\n",
        "client.switch_database(database)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "def prepare_data_for_model(data, scale=True, scaler_type=StandardScaler):\n",
        "    data = scaler_type().fit_transform(data)\n",
        "    #if len(data) > sequence_length:\n",
        "    #    data = data[-sequence_length:-1]\n",
        "    \n",
        "    Xs = []\n",
        "    Xs.append(data)\n",
        "    return np.array(Xs)\n",
        "\n",
        "\n",
        "mse = keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.AUTO)\n",
        "\n",
        "def collect_data_and_run_model(model, timestamp, sequence_length, group_by):\n",
        "    max_time = int(timestamp.timestamp() * 1000)\n",
        "    min_time = int((timestamp - parse_time(sequence_length)).timestamp() * 1000)\n",
        "    data = get_data_from_influxDB(measurements, 'plc', min_time, max_time, group_by)\n",
        "\n",
        "    if data is None:\n",
        "        return -1\n",
        "\n",
        "    data = data.to_numpy()\n",
        "    np.reshape(data, (1, data.shape[0], data.shape[1]))\n",
        "\n",
        "    data = prepare_data_for_model(data)\n",
        "    \n",
        "    res = model.predict(data)\n",
        "    loss = mse(data, res).numpy()\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "!pip install paho-mqtt\n",
        "import paho.mqtt.client as mqtt\n",
        "\n",
        "mqtt_host                = \"demo2.iotstack.co\"\n",
        "mqtt_user_name           = \"pubclient\"\n",
        "mqtt_password            = \"tiguitto\"\n",
        "mqtt_port                = 8883\n",
        "mqtt_keepalive           = 60\n",
        "\n",
        "mqtt_client = mqtt.Client()\n",
        "mqtt_client._username = mqtt_user_name\n",
        "mqtt_client._password = mqtt_password\n",
        "mqtt_client.tls_set()\n",
        "mqtt_client.connect(mqtt_host, mqtt_port, mqtt_keepalive)\n",
        "\n",
        "def get_influx_ts(ts):\n",
        "    base_ts = datetime(1677, 9, 21, 0, 12, 43, 145224)\n",
        "    base_ns = -9223372036854775806\n",
        "\n",
        "    delta_ts = ts - base_ts\n",
        "    delta_ns = delta_ts.total_seconds()*1000000000\n",
        "    \n",
        "    ts_ns = base_ns + delta_ns\n",
        "\n",
        "    return \"{:.0f}\".format(ts_ns)\n",
        "\n",
        "def send_result_mqtt(timestamp, tag_addition, loss, model_name, sequence_length, group_by, sequence_step):\n",
        "    ts = get_influx_ts(timestamp)\n",
        "\n",
        "    msg = \"evaluation\"\n",
        "    msg += \",\"\n",
        "\n",
        "    msg += tag_addition\n",
        "    msg += \",\"\n",
        "\n",
        "    msg += \"model_name=\"\n",
        "    msg += model_name\n",
        "    msg += \",\"\n",
        "    msg += \"sequence_length=\"\n",
        "    msg += sequence_length\n",
        "    msg += \",\"\n",
        "    msg += \"group_by=\"\n",
        "    msg += group_by\n",
        "    msg += \",\"\n",
        "    msg += \"sequence_step=\"\n",
        "    msg += sequence_step\n",
        "    \n",
        "    msg += \" \"\n",
        "    msg += \"loss=\"\n",
        "    msg += str(loss)\n",
        "    \n",
        "    msg += \" \"\n",
        "    msg += str(ts)\n",
        "    print(msg)\n",
        "\n",
        "    mqtt_client.publish(\"IOT/test\", msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ2wlivDXKTP",
        "outputId": "71ebbfc9-ee84-42ba-ac96-2a1c7d6f00c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (LSTM)            (None, 288, 64)           18944     \n",
            "                                                                 \n",
            " encoder_2 (LSTM)            (None, 288, 32)           12416     \n",
            "                                                                 \n",
            " encoder_3 (LSTM)            (None, 16)                3136      \n",
            "                                                                 \n",
            " encoder_decoder_bridge (Rep  (None, 288, 16)          0         \n",
            " eatVector)                                                      \n",
            "                                                                 \n",
            " decoder_1 (LSTM)            (None, 288, 16)           2112      \n",
            "                                                                 \n",
            " decoder_2 (LSTM)            (None, 288, 32)           6272      \n",
            "                                                                 \n",
            " decoder_3 (LSTM)            (None, 288, 64)           24832     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 288, 9)           585       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,297\n",
            "Trainable params: 68,297\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "reconstructed_model = keras.models.load_model(model_name)\n",
        "reconstructed_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Fr7HE0aXJJ",
        "outputId": "d0de0169-377a-4a5a-90ff-4fade1413d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-01 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1630454400000000000\n",
            "2021-09-02 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1630540800000000000\n",
            "2021-09-03 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1630627200000000000\n",
            "2021-09-04 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1630713600000000000\n",
            "2021-09-05 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1630800000000000000\n",
            "2021-09-06 00:00:00  -  1.025598\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.025598 1630886400000000000\n",
            "2021-09-07 00:00:00  -  1.0659449\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0659449 1630972800000000000\n",
            "2021-09-08 00:00:00  -  1.2199756\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2199756 1631059200000000000\n",
            "2021-09-09 00:00:00  -  1.4327197\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.4327197 1631145600000000000\n",
            "2021-09-10 00:00:00  -  0.7331314\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.7331314 1631232000000000000\n",
            "2021-09-11 00:00:00  -  0.68402356\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.68402356 1631318400000000000\n",
            "2021-09-12 00:00:00  -  1.5282403\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.5282403 1631404800000000000\n",
            "2021-09-13 00:00:00  -  1.2381662\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2381662 1631491200000000000\n",
            "2021-09-14 00:00:00  -  1.2357707\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2357707 1631577600000000000\n",
            "2021-09-15 00:00:00  -  1.2404264\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2404264 1631664000000000000\n",
            "2021-09-16 00:00:00  -  1.4441046\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.4441046 1631750400000000000\n",
            "2021-09-17 00:00:00  -  1.1877954\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.1877954 1631836800000000000\n",
            "2021-09-18 00:00:00  -  1.2488949\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2488949 1631923200000000000\n",
            "2021-09-19 00:00:00  -  1.2932572\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2932572 1632009600000000000\n",
            "2021-09-20 00:00:00  -  0.99176174\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.99176174 1632096000000000000\n",
            "2021-09-21 00:00:00  -  0.7710753\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.7710753 1632182400000000000\n",
            "2021-09-22 00:00:00  -  1.1786025\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.1786025 1632268800000000000\n",
            "2021-09-23 00:00:00  -  1.2751861\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2751861 1632355200000000000\n",
            "2021-09-24 00:00:00  -  1.2607685\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2607685 1632441600000000000\n",
            "2021-09-25 00:00:00  -  1.3103994\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3103994 1632528000000000000\n",
            "2021-09-26 00:00:00  -  1.2644283\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2644283 1632614400000000000\n",
            "2021-09-27 00:00:00  -  0.91761005\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.91761005 1632700800000000000\n",
            "2021-09-28 00:00:00  -  0.6589134\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.6589134 1632787200000000000\n",
            "2021-09-29 00:00:00  -  1.0010936\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0010936 1632873600000000000\n",
            "2021-09-30 00:00:00  -  1.2221848\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2221848 1632960000000000000\n",
            "2021-10-01 00:00:00  -  0.6655894\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.6655894 1633046400000000000\n",
            "2021-10-02 00:00:00  -  2.5310822\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=2.5310822 1633132800000000000\n",
            "2021-10-03 00:00:00  -  1.3397852\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3397852 1633219200000000000\n",
            "2021-10-04 00:00:00  -  1.3524727\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3524727 1633305600000000000\n",
            "2021-10-05 00:00:00  -  1.3368472\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3368472 1633392000000000000\n",
            "2021-10-06 00:00:00  -  0.9925018\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.9925018 1633478400000000000\n",
            "2021-10-07 00:00:00  -  1.1618179\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.1618179 1633564800000000000\n",
            "2021-10-08 00:00:00  -  1.2763081\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2763081 1633651200000000000\n",
            "2021-10-09 00:00:00  -  1.0850996\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0850996 1633737600000000000\n",
            "2021-10-10 00:00:00  -  1.4004288\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.4004288 1633824000000000000\n",
            "2021-10-11 00:00:00  -  1.2252187\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2252187 1633910400000000000\n",
            "2021-10-12 00:00:00  -  0.7887452\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.7887452 1633996800000000000\n",
            "2021-10-13 00:00:00  -  1.3462737\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3462737 1634083200000000000\n",
            "2021-10-14 00:00:00  -  1.347672\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.347672 1634169600000000000\n",
            "2021-10-15 00:00:00  -  1.2012575\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2012575 1634256000000000000\n",
            "2021-10-16 00:00:00  -  0.81907535\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.81907535 1634342400000000000\n",
            "2021-10-17 00:00:00  -  1.2656502\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2656502 1634428800000000000\n",
            "2021-10-18 00:00:00  -  1.2291099\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2291099 1634515200000000000\n",
            "2021-10-19 00:00:00  -  1.2914268\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2914268 1634601600000000000\n",
            "2021-10-20 00:00:00  -  1.215329\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.215329 1634688000000000000\n",
            "2021-10-21 00:00:00  -  1.3245493\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3245493 1634774400000000000\n",
            "2021-10-22 00:00:00  -  1.2849694\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2849694 1634860800000000000\n",
            "2021-10-23 00:00:00  -  2.855444\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=2.855444 1634947200000000000\n",
            "2021-10-24 00:00:00  -  2.5234165\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=2.5234165 1635033600000000000\n",
            "2021-10-25 00:00:00  -  0.960507\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.960507 1635120000000000000\n",
            "2021-10-26 00:00:00  -  0.91513073\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.91513073 1635206400000000000\n",
            "2021-10-27 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1635292800000000000\n",
            "2021-10-28 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1635379200000000000\n",
            "2021-10-29 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1635465600000000000\n",
            "2021-10-30 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1635552000000000000\n",
            "2021-10-31 00:00:00  -  -1\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=-1 1635638400000000000\n",
            "2021-11-01 00:00:00  -  1.6579012\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.6579012 1635724800000000000\n",
            "2021-11-02 00:00:00  -  1.2106671\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2106671 1635811200000000000\n",
            "2021-11-03 00:00:00  -  1.2406389\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2406389 1635897600000000000\n",
            "2021-11-04 00:00:00  -  1.2564136\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2564136 1635984000000000000\n",
            "2021-11-05 00:00:00  -  0.84683055\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.84683055 1636070400000000000\n",
            "2021-11-06 00:00:00  -  1.2178941\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2178941 1636156800000000000\n",
            "2021-11-07 00:00:00  -  1.3866031\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3866031 1636243200000000000\n",
            "2021-11-08 00:00:00  -  3.4638796\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=3.4638796 1636329600000000000\n",
            "2021-11-09 00:00:00  -  1.22792\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.22792 1636416000000000000\n",
            "2021-11-10 00:00:00  -  1.322667\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.322667 1636502400000000000\n",
            "2021-11-11 00:00:00  -  1.0285046\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0285046 1636588800000000000\n",
            "2021-11-12 00:00:00  -  1.5786104\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.5786104 1636675200000000000\n",
            "2021-11-13 00:00:00  -  0.8127957\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.8127957 1636761600000000000\n",
            "2021-11-14 00:00:00  -  1.0739119\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0739119 1636848000000000000\n",
            "2021-11-15 00:00:00  -  1.0215645\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0215645 1636934400000000000\n",
            "2021-11-16 00:00:00  -  1.3719747\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3719747 1637020800000000000\n",
            "2021-11-17 00:00:00  -  1.2455692\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2455692 1637107200000000000\n",
            "2021-11-18 00:00:00  -  1.3312199\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3312199 1637193600000000000\n",
            "2021-11-19 00:00:00  -  1.2735331\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2735331 1637280000000000000\n",
            "2021-11-20 00:00:00  -  1.7867601\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.7867601 1637366400000000000\n",
            "2021-11-21 00:00:00  -  1.12332\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.12332 1637452800000000000\n",
            "2021-11-22 00:00:00  -  0.80983686\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.80983686 1637539200000000000\n",
            "2021-11-23 00:00:00  -  0.75760055\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.75760055 1637625600000000000\n",
            "2021-11-24 00:00:00  -  1.2644804\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2644804 1637712000000000000\n",
            "2021-11-25 00:00:00  -  2.323751\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=2.323751 1637798400000000000\n",
            "2021-11-26 00:00:00  -  1.0959523\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0959523 1637884800000000000\n",
            "2021-11-27 00:00:00  -  1.3302649\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3302649 1637971200000000000\n",
            "2021-11-28 00:00:00  -  0.8745408\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.8745408 1638057600000000000\n",
            "2021-11-29 00:00:00  -  0.80058324\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.80058324 1638144000000000000\n",
            "2021-11-30 00:00:00  -  1.2303165\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2303165 1638230400000000000\n",
            "2021-12-01 00:00:00  -  0.7905281\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.7905281 1638316800000000000\n",
            "2021-12-02 00:00:00  -  1.0429243\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.0429243 1638403200000000000\n",
            "2021-12-03 00:00:00  -  1.4900376\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.4900376 1638489600000000000\n",
            "2021-12-04 00:00:00  -  1.3934966\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3934966 1638576000000000000\n",
            "2021-12-05 00:00:00  -  1.4493147\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.4493147 1638662400000000000\n",
            "2021-12-06 00:00:00  -  1.2221073\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2221073 1638748800000000000\n",
            "2021-12-07 00:00:00  -  1.3896887\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3896887 1638835200000000000\n",
            "2021-12-08 00:00:00  -  1.2976267\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2976267 1638921600000000000\n",
            "2021-12-09 00:00:00  -  1.393991\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.393991 1639008000000000000\n",
            "2021-12-10 00:00:00  -  1.2743247\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2743247 1639094400000000000\n",
            "2021-12-11 00:00:00  -  0.76582885\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.76582885 1639180800000000000\n",
            "2021-12-12 00:00:00  -  0.8994943\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.8994943 1639267200000000000\n",
            "2021-12-13 00:00:00  -  0.97914\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.97914 1639353600000000000\n",
            "2021-12-14 00:00:00  -  1.2838591\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2838591 1639440000000000000\n",
            "2021-12-15 00:00:00  -  1.377517\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.377517 1639526400000000000\n",
            "2021-12-16 00:00:00  -  1.2875631\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2875631 1639612800000000000\n",
            "2021-12-17 00:00:00  -  1.3145466\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3145466 1639699200000000000\n",
            "2021-12-18 00:00:00  -  2.3916028\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=2.3916028 1639785600000000000\n",
            "2021-12-19 00:00:00  -  1.2336974\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2336974 1639872000000000000\n",
            "2021-12-20 00:00:00  -  1.1369063\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.1369063 1639958400000000000\n",
            "2021-12-21 00:00:00  -  0.9443139\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.9443139 1640044800000000000\n",
            "2021-12-22 00:00:00  -  0.7550727\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=0.7550727 1640131200000000000\n",
            "2021-12-23 00:00:00  -  1.322149\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.322149 1640217600000000000\n",
            "2021-12-24 00:00:00  -  1.3699574\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.3699574 1640304000000000000\n",
            "2021-12-25 00:00:00  -  2.7465765\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=2.7465765 1640390400000000000\n",
            "2021-12-26 00:00:00  -  1.451271\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.451271 1640476800000000000\n",
            "2021-12-27 00:00:00  -  1.4265904\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.4265904 1640563200000000000\n",
            "2021-12-28 00:00:00  -  1.238641\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.238641 1640649600000000000\n",
            "2021-12-29 00:00:00  -  1.2323818\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2323818 1640736000000000000\n",
            "2021-12-30 00:00:00  -  1.2307487\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2307487 1640822400000000000\n",
            "2021-12-31 00:00:00  -  1.2297683\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2297683 1640908800000000000\n",
            "2022-01-01 00:00:00  -  1.2330053\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2330053 1640995200000000000\n",
            "2022-01-02 00:00:00  -  1.2347635\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2347635 1641081600000000000\n",
            "2022-01-03 00:00:00  -  1.2379861\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2379861 1641168000000000000\n",
            "2022-01-04 00:00:00  -  1.2456231\n",
            "evaluation,tank_group=1,model_name=autoencoder_tg1_2,sequence_length=1d,group_by=5m,sequence_step=1d loss=1.2456231 1641254400000000000\n"
          ]
        }
      ],
      "source": [
        "timestamp = datetime.fromisoformat('2021-09-01+00:00') # ('2022-01-01')\n",
        "\n",
        "while(timestamp < datetime.fromisoformat('2022-01-05')):\n",
        "    loss = collect_data_and_run_model(reconstructed_model, timestamp, sequence_length, group_by)\n",
        "    print(timestamp, \" - \", loss)\n",
        "    send_result_mqtt(timestamp, mqtt_addition, loss, model_name, sequence_length, group_by, sequence_step)\n",
        "    timestamp += parse_time(sequence_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU1i7uMSIJRR",
        "outputId": "ce7ae0f4-147c-43b4-fe4e-465fb79360db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "845/845 [==============================] - 35s 42ms/step - loss: 0.6384\n"
          ]
        }
      ],
      "source": [
        "feats, _, _, XX, YY = generate_datasets_for_validation(test_data, window_length)\n",
        "eval = model.evaluate(x=XX, y=YY, batch_size=batch_size, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZqttdDLLWaV",
        "outputId": "3cad46af-36e5-46d2-a01b-8514d142f10d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "158/158 [==============================] - 7s 42ms/step - loss: 0.1220\n"
          ]
        }
      ],
      "source": [
        "feats, X, Y, XX, YY = generate_datasets_for_training(train_data, window_length)\n",
        "eval = model.evaluate(x=XX, y=YY, batch_size=batch_size, return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClMHp53VN2mT"
      },
      "outputs": [],
      "source": [
        "val = XX[0:59]\n",
        "val_pred = model.predict(XX, batch_size=batch_size)\n",
        "#print(val_pred)\n",
        "\n",
        "mse = keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "loss = mse(XX, val_pred).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRmCBcASVifh",
        "outputId": "797f80b7-6719-4477-97d5-1f1832adb031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5025,)\n",
            "[0.14081083 0.05040515 0.05924203 ... 0.09286948 0.09163727 0.06387298]\n"
          ]
        }
      ],
      "source": [
        "l = np.mean(loss,axis=1)\n",
        "print(l.shape)\n",
        "print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U_KKyjBP5A2",
        "outputId": "5af5a1bb-ad90-48d8-dcc0-298575ed0036"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08521775"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse = keras.losses.MeanSquaredError()\n",
        "mse(val, val_pred).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "Z1pExnLPQuCp",
        "outputId": "0874c58a-5f52-4ed3-8d0b-1e34ee9a5908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.08521775\n",
            "0.08382894\n",
            "0.083848566\n",
            "0.08469069\n",
            "0.084640406\n",
            "0.08465851\n",
            "0.084799886\n",
            "0.085361406\n",
            "0.08993405\n",
            "0.08883081\n",
            "0.08994052\n",
            "0.09011304\n",
            "0.0900291\n",
            "0.091042876\n",
            "0.08940987\n",
            "0.08883122\n",
            "0.088545345\n",
            "0.0882771\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-bedf39060fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m59\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1817\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_pss_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "mse = keras.losses.MeanSquaredError()\n",
        "for i in range(0, len(XX)-60):\n",
        "    val = XX[i:i+59]\n",
        "    val_pred = model.predict(val, batch_size=batch_size)\n",
        "    e = mse(val, val_pred).numpy()\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_tY_Kzj8n-z",
        "outputId": "c09e8d0a-e059-4277-a069-4a499b05be85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5025 2940 14773500\n"
          ]
        }
      ],
      "source": [
        "print(len(XX), XX[0].size, XX.size)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-mOx7vh_skiY",
        "Mmh2zGuYtaoL",
        "CNTQfZIGssHc"
      ],
      "name": "SWMS_lstm_autoencoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}